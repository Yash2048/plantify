{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T19:36:51.610326Z",
     "iopub.status.busy": "2025-02-27T19:36:51.609942Z",
     "iopub.status.idle": "2025-02-27T19:37:21.345207Z",
     "shell.execute_reply": "2025-02-27T19:37:21.344056Z",
     "shell.execute_reply.started": "2025-02-27T19:36:51.610295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'indicleaf123.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Set the root directory (Main_Dataset_Folder) containing the master folders\n",
    "root_dir = r\"/kaggle/input/indic-leaf-ds/Indic-Leaf-Dataset-master/Indic-Leaf-Dataset-master/indic_leaf_dataset\"  # change this to your main dataset folder path\n",
    "output_csv = \"indicleaf123.csv\"\n",
    "\n",
    "def extract_class_label(folder_name):\n",
    "    \"\"\"\n",
    "    Extracts the class label by splitting the folder name on the first underscore.\n",
    "    E.g., \"001_Rose\" returns \"Rose\". If no underscore exists, returns the folder name.\n",
    "    \"\"\"\n",
    "    if \"_\" in folder_name:\n",
    "        return folder_name.split(\"_\", 1)[1]\n",
    "    return folder_name\n",
    "\n",
    "# Open CSV file for writing\n",
    "with open(output_csv, mode=\"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"filepath\", \"class_label\"])  # CSV header\n",
    "\n",
    "    # Loop over each master folder in the root directory\n",
    "    for master_folder_name in os.listdir(root_dir):\n",
    "        master_folder = os.path.join(root_dir, master_folder_name)\n",
    "        if os.path.isdir(master_folder):\n",
    "            # Extract class label from master folder name (remove number_ prefix)\n",
    "            class_label = extract_class_label(master_folder_name)\n",
    "            # Walk through all subdirectories under the master folder\n",
    "            for subdir, _, files in os.walk(master_folder):\n",
    "                for file in files:\n",
    "                    # Check if the file is an image (adjust extensions if needed)\n",
    "                    if file.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".gif\")):\n",
    "                        file_path = os.path.join(subdir, file)\n",
    "                        writer.writerow([file_path, class_label])\n",
    "\n",
    "print(f\"CSV file '{output_csv}' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T19:39:40.430336Z",
     "iopub.status.busy": "2025-02-27T19:39:40.429838Z",
     "iopub.status.idle": "2025-02-27T19:42:31.312808Z",
     "shell.execute_reply": "2025-02-27T19:42:31.311178Z",
     "shell.execute_reply.started": "2025-02-27T19:39:40.430295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing /kaggle/input/indic-leaf-ds/Indic-Leaf-Dataset-master/Indic-Leaf-Dataset-master/indic_leaf_dataset/99_ti_plant/level_3/IMG_20180825_155235.jpg: cannot identify image file '/kaggle/input/indic-leaf-ds/Indic-Leaf-Dataset-master/Indic-Leaf-Dataset-master/indic_leaf_dataset/99_ti_plant/level_3/IMG_20180825_155235.jpg'\n",
      "Removing /kaggle/input/indic-leaf-ds/Indic-Leaf-Dataset-master/Indic-Leaf-Dataset-master/indic_leaf_dataset/49_spider_lily/level_1/IMG_20180821_170400.jpg: cannot identify image file '/kaggle/input/indic-leaf-ds/Indic-Leaf-Dataset-master/Indic-Leaf-Dataset-master/indic_leaf_dataset/49_spider_lily/level_1/IMG_20180821_170400.jpg'\n",
      "Removing /kaggle/input/indic-leaf-ds/Indic-Leaf-Dataset-master/Indic-Leaf-Dataset-master/indic_leaf_dataset/95_royal_palm/level_3/IMG_20180518_171351.jpg: cannot identify image file '/kaggle/input/indic-leaf-ds/Indic-Leaf-Dataset-master/Indic-Leaf-Dataset-master/indic_leaf_dataset/95_royal_palm/level_3/IMG_20180518_171351.jpg'\n",
      "Cleaned CSV saved with 28005 rows (out of 28008)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, UnidentifiedImageError\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv('/kaggle/input/indiccsv/indicleaf123.csv')\n",
    "\n",
    "# Define a function to check image validity\n",
    "def is_valid_image(path):\n",
    "    try:\n",
    "        with Image.open(path) as img:\n",
    "            img.verify()  # Check image integrity\n",
    "        return True\n",
    "    except (UnidentifiedImageError, Exception) as e:\n",
    "        print(f\"Removing {path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Apply the function to each row's filepath.\n",
    "# This returns a boolean Series.\n",
    "mask = df['filepath'].apply(is_valid_image)\n",
    "\n",
    "# Filter the DataFrame for valid images\n",
    "df_clean = df[mask].reset_index(drop=True)\n",
    "\n",
    "# Optionally, save the cleaned CSV\n",
    "df_clean.to_csv('cleaned_indicleaf.csv', index=False)\n",
    "print(f\"Cleaned CSV saved with {len(df_clean)} rows (out of {len(df)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T19:58:55.791265Z",
     "iopub.status.busy": "2025-02-27T19:58:55.791042Z",
     "iopub.status.idle": "2025-02-28T00:09:19.699826Z",
     "shell.execute_reply": "2025-02-28T00:09:19.698984Z",
     "shell.execute_reply.started": "2025-02-27T19:58:55.791243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22384 validated image filenames belonging to 112 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 20 invalid image filename(s) in x_col=\"filepath\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5595 validated image filenames belonging to 112 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 6 invalid image filename(s) in x_col=\"filepath\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_base_notop.h5\n",
      "\u001b[1m350926856/350926856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 1s/step - accuracy: 0.1560 - loss: 4.1071 - val_accuracy: 0.6055 - val_loss: 2.0164\n",
      "Epoch 2/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 675ms/step - accuracy: 0.5930 - loss: 1.9128 - val_accuracy: 0.7369 - val_loss: 1.2465\n",
      "Epoch 3/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 665ms/step - accuracy: 0.7036 - loss: 1.2980 - val_accuracy: 0.7786 - val_loss: 0.9863\n",
      "Epoch 4/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 665ms/step - accuracy: 0.7632 - loss: 1.0139 - val_accuracy: 0.8077 - val_loss: 0.8367\n",
      "Epoch 5/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 661ms/step - accuracy: 0.7923 - loss: 0.8655 - val_accuracy: 0.8211 - val_loss: 0.7448\n",
      "Epoch 6/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 659ms/step - accuracy: 0.8193 - loss: 0.7397 - val_accuracy: 0.8340 - val_loss: 0.6793\n",
      "Epoch 7/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 659ms/step - accuracy: 0.8340 - loss: 0.6817 - val_accuracy: 0.8445 - val_loss: 0.6308\n",
      "Epoch 8/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 661ms/step - accuracy: 0.8555 - loss: 0.6112 - val_accuracy: 0.8524 - val_loss: 0.5890\n",
      "Epoch 9/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 667ms/step - accuracy: 0.8601 - loss: 0.5527 - val_accuracy: 0.8567 - val_loss: 0.5624\n",
      "Epoch 10/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 663ms/step - accuracy: 0.8729 - loss: 0.5205 - val_accuracy: 0.8649 - val_loss: 0.5294\n",
      "Epoch 11/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 662ms/step - accuracy: 0.8811 - loss: 0.4887 - val_accuracy: 0.8695 - val_loss: 0.5103\n",
      "Epoch 12/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 666ms/step - accuracy: 0.8862 - loss: 0.4572 - val_accuracy: 0.8718 - val_loss: 0.4938\n",
      "Epoch 13/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 667ms/step - accuracy: 0.8897 - loss: 0.4282 - val_accuracy: 0.8767 - val_loss: 0.4730\n",
      "Epoch 14/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 662ms/step - accuracy: 0.8989 - loss: 0.3989 - val_accuracy: 0.8844 - val_loss: 0.4580\n",
      "Epoch 15/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 656ms/step - accuracy: 0.9032 - loss: 0.3874 - val_accuracy: 0.8815 - val_loss: 0.4562\n",
      "Epoch 16/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 661ms/step - accuracy: 0.9064 - loss: 0.3656 - val_accuracy: 0.8849 - val_loss: 0.4435\n",
      "Epoch 17/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 661ms/step - accuracy: 0.9215 - loss: 0.3065 - val_accuracy: 0.8920 - val_loss: 0.4173\n",
      "Epoch 20/20\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 661ms/step - accuracy: 0.9257 - loss: 0.2939 - val_accuracy: 0.8947 - val_loss: 0.4054\n",
      "Epoch 1/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 828ms/step - accuracy: 0.9066 - loss: 0.3346 - val_accuracy: 0.9176 - val_loss: 0.3138 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 799ms/step - accuracy: 0.9585 - loss: 0.1453 - val_accuracy: 0.9205 - val_loss: 0.3015 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 797ms/step - accuracy: 0.9748 - loss: 0.0857 - val_accuracy: 0.9299 - val_loss: 0.2752 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 799ms/step - accuracy: 0.9852 - loss: 0.0545 - val_accuracy: 0.9346 - val_loss: 0.2594 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 793ms/step - accuracy: 0.9884 - loss: 0.0408 - val_accuracy: 0.9328 - val_loss: 0.2977 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 798ms/step - accuracy: 0.9883 - loss: 0.0388 - val_accuracy: 0.9358 - val_loss: 0.2767 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 797ms/step - accuracy: 0.9906 - loss: 0.0310 - val_accuracy: 0.9373 - val_loss: 0.2717 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 798ms/step - accuracy: 0.9928 - loss: 0.0273 - val_accuracy: 0.9407 - val_loss: 0.2789 - learning_rate: 1.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 793ms/step - accuracy: 0.9933 - loss: 0.0226 - val_accuracy: 0.9382 - val_loss: 0.2854 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 220 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 431ms/step - accuracy: 0.8926 - loss: 0.4103\n",
      "Validation Loss: 0.40541499853134155, Validation Accuracy: 0.8947274088859558\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 448ms/step\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "          acalypa       0.98      0.91      0.95        67\n",
      "african_milk_tree       1.00      0.85      0.92        13\n",
      "        air_plant       0.94      0.94      0.94        54\n",
      "   allamanda_pink       0.95      0.86      0.90        49\n",
      "             amla       0.92      0.84      0.88        56\n",
      "       arrow_head       0.89      0.92      0.91        63\n",
      "     ashokachettu       0.90      0.93      0.92        71\n",
      "            badam       0.87      0.91      0.89        64\n",
      "           bamboo       0.98      0.96      0.97        45\n",
      "           banana       1.00      0.94      0.97        36\n",
      "           banyan       0.79      0.84      0.82        58\n",
      "       blackberry       0.91      0.82      0.87        51\n",
      "          boxwood       0.86      0.72      0.78        68\n",
      "          brinjal       0.87      0.91      0.89        22\n",
      "   butterfly_palm       0.96      0.96      0.96        50\n",
      " caladium_bicolor       0.97      0.91      0.94        43\n",
      "      candle_bush       0.97      0.95      0.96        65\n",
      "            canna       0.94      1.00      0.97        47\n",
      "cape_honey_suckle       0.92      0.89      0.91        55\n",
      "           cashew       0.98      0.91      0.95        57\n",
      "           castor       0.98      0.98      0.98        53\n",
      "        colocasia       0.94      0.92      0.93        63\n",
      "     curry_leaves       0.92      0.96      0.94        50\n",
      "    custard_apple       0.72      0.91      0.80        53\n",
      "       delphinium       0.95      0.95      0.95        19\n",
      "      dragon_tree       0.95      0.98      0.97        58\n",
      "        drumstick       0.94      0.94      0.94        47\n",
      "         dumbcane       0.98      0.96      0.97        54\n",
      "             etha       0.92      1.00      0.96        58\n",
      "        euphorbia       0.96      0.94      0.95        70\n",
      "     four_o_clock       0.92      0.91      0.92        66\n",
      "     foxtail_palm       0.81      0.88      0.85        34\n",
      "          gandham       0.81      0.84      0.83        51\n",
      "          ganneru       1.00      0.93      0.96        27\n",
      "            gauva       0.94      0.87      0.90        54\n",
      "       gliricidia       0.85      0.85      0.85        53\n",
      "        gold_dust       0.88      0.94      0.91        70\n",
      "   gold_spot_thin       1.00      0.96      0.98        28\n",
      "  golden_trumphet       0.91      0.80      0.85        54\n",
      "         gulmohar       0.96      0.86      0.91        59\n",
      "   indian_rhubarb       0.97      0.93      0.95        30\n",
      "     indian_tulip       0.84      0.85      0.85        61\n",
      "          insulin       0.98      0.94      0.96        47\n",
      "ixora_bright_pink       0.77      0.53      0.62        38\n",
      "  ixora_dark_pink       0.94      0.79      0.86        38\n",
      "     ixora_orange       0.74      0.79      0.76        43\n",
      "    ixora_scarlet       0.78      0.82      0.80        34\n",
      "        jackfruit       0.51      0.96      0.66        46\n",
      "  jasmine_arabian       0.92      0.81      0.86        43\n",
      "    jasmine_crape       0.89      0.83      0.86        48\n",
      " jasmine_pinwheel       0.81      0.81      0.81        53\n",
      "    junglee_kikar       0.71      0.71      0.71        14\n",
      "          kadamba       0.82      0.93      0.87        67\n",
      "           kamala       0.69      0.69      0.69        52\n",
      "     kanakambaram       0.89      0.89      0.89        46\n",
      "       kanchanara       0.87      0.95      0.91        58\n",
      "           kanuga       0.86      0.79      0.83        48\n",
      "          karanda       0.91      0.87      0.89        85\n",
      "          lantana       0.95      0.90      0.93        62\n",
      "            lemon       0.69      0.82      0.75        51\n",
      "          lipstic       0.78      0.96      0.86        51\n",
      "         mandaram       0.93      0.84      0.88        49\n",
      "            mango       0.82      0.95      0.88        57\n",
      "         marigold       0.97      1.00      0.99        33\n",
      "   mauritius_hemp       0.89      0.92      0.90        36\n",
      "      money_plant       0.85      0.98      0.91        59\n",
      "          mosambe       0.69      0.75      0.72        55\n",
      "          nalleru       0.92      0.92      0.92        52\n",
      "             neem       0.93      0.94      0.93        66\n",
      "         oleander       0.94      0.95      0.94        61\n",
      "           papaya       0.95      1.00      0.98        42\n",
      "       paper_leaf       0.93      0.90      0.92        30\n",
      "   peacock_flower       0.80      0.90      0.85        59\n",
      "     peacock_tail       1.00      0.94      0.97        47\n",
      "   perfume_flower       1.00      0.79      0.88        61\n",
      "       periwinkle       0.97      0.94      0.96        68\n",
      "       pink_paper       0.93      0.87      0.90        47\n",
      "      pink_shower       0.90      0.95      0.92        58\n",
      "         plumbago       0.93      0.89      0.91        56\n",
      "         plumeria       0.94      0.94      0.94        65\n",
      "       poinsettia       0.97      0.95      0.96        40\n",
      "      pomegranate       0.81      0.84      0.83        45\n",
      "     pulla_jemudu       0.96      0.96      0.96        24\n",
      "          pumpkin       0.86      0.86      0.86        14\n",
      "             rela       0.86      0.90      0.88        48\n",
      "     repalachettu       0.80      0.75      0.78        44\n",
      "             rose       1.00      0.94      0.97        16\n",
      "       royal_palm       0.98      0.85      0.91        55\n",
      "        sago_palm       1.00      1.00      1.00        56\n",
      "           sapota       0.94      0.89      0.91        66\n",
      "      sarpagandha       0.97      0.89      0.93        63\n",
      "     sausage_tree       0.88      0.87      0.87        76\n",
      "       schefflera       0.96      0.96      0.96        49\n",
      "  singapore_daisy       1.00      0.99      0.99        79\n",
      "        snoutbean       0.79      0.82      0.81        38\n",
      "    song_of_india       0.86      0.90      0.88        63\n",
      "   spanish_cherry       0.74      0.77      0.75        60\n",
      "      spider_lily       0.95      1.00      0.97        58\n",
      "     spider_plant       0.97      0.86      0.91        70\n",
      "     star_cluster       1.00      0.90      0.95        63\n",
      "          subabul       0.75      0.67      0.71        18\n",
      "         tamarind       0.84      0.93      0.88        61\n",
      "          tangedu       0.77      0.80      0.78        45\n",
      "             taro       0.93      0.88      0.90        43\n",
      "      thorn_apple       0.95      0.95      0.95        38\n",
      "        thotakura       1.00      0.67      0.80         3\n",
      "         ti_plant       0.98      0.97      0.97        58\n",
      "       touch_tree       0.98      0.91      0.94        53\n",
      "            tulsi       0.96      0.94      0.95        68\n",
      "      weeping_fig       0.87      0.81      0.84        59\n",
      "   whistling_pine       0.97      0.97      0.97        39\n",
      "     zigzag_plant       1.00      0.92      0.96        12\n",
      "\n",
      "         accuracy                           0.89      5595\n",
      "        macro avg       0.90      0.89      0.89      5595\n",
      "     weighted avg       0.90      0.89      0.90      5595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fine tune\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from tensorflow.keras.applications import ConvNeXtBase\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping , ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.convnext import preprocess_input\n",
    "from PIL import ImageFile\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Enable loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Load and prepare the CSV data\n",
    "df = pd.read_csv('/kaggle/input/indiccsv/cleaned_indicleaf.csv')\n",
    "df['filepath'] = df['filepath'].astype(str)\n",
    "df['class_label'] = df['class_label'].astype(str)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split data into train and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['class_label'])\n",
    "\n",
    "# Create data generators with ConvNeXt preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# Generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filepath',\n",
    "    y_col='class_label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='filepath',\n",
    "    y_col='class_label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get number of classes\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# Build ConvNeXtBase model\n",
    "base_model = ConvNeXtBase(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom head\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile with higher learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),  \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint, early_stop]\n",
    ")\n",
    "\n",
    "# Fine-tuning phase: unfreeze top layers\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-80]:  # Unfreeze last 80 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='sparscategorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fine-tuning callbacks\n",
    "fine_tune_callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        'fine_tuned_model.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max'\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        min_lr=1e-7\n",
    "    )\n",
    "]\n",
    "\n",
    "# Fine-tuning training\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=fine_tune_callbacks\n",
    ")\n",
    "\n",
    "# Load best weights and save final model\n",
    "model.load_weights('best_model.keras')\n",
    "model.save('plant_classification_indic_convnext.keras')\n",
    "\n",
    "# Evaluation\n",
    "results = model.evaluate(val_generator)\n",
    "print(f'Validation Loss: {results[0]}, Validation Accuracy: {results[1]}')\n",
    "\n",
    "val_preds = model.predict(val_generator, verbose=1)\n",
    "val_preds_class = np.argmax(val_preds, axis=1)\n",
    "\n",
    "true_labels = val_generator.classes\n",
    "label_map = {v: k for k, v in train_generator.class_indices.items()}\n",
    "target_names = [label_map[i] for i in range(num_classes)]\n",
    "\n",
    "report = classification_report(true_labels, val_preds_class, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-28T01:31:55.584Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Assume your CSV has a column 'class_label'\n",
    "df = pd.read_csv('/kaggle/input/indiccsv/cleaned_indicleaf.csv')\n",
    "\n",
    "# Initialize and fit the encoder on your class labels\n",
    "encoder = LabelEncoder()\n",
    "df['encoded_label'] = encoder.fit_transform(df['class_label'])\n",
    "\n",
    "# Optionally, you can save the encoder for later use in prediction\n",
    "joblib.dump(encoder, 'label_encoder.pkl')\n",
    "\n",
    "# Continue with your training process using the 'encoded_label' column or your generator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import joblib\n",
    "\n",
    "def predict_image(image_path, model_path, encoder_path=None):\n",
    "    # Load the trained model (.keras format)\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(image_path, target_size=(224, 224), color_mode='rgb')\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Predict the class probabilities\n",
    "    predictions = model.predict(img_array)\n",
    "    \n",
    "    # Get the index of the most dominant class\n",
    "    dominant_index = np.argmax(predictions, axis=1)[0]\n",
    "    \n",
    "    # If an encoder path is provided, load the encoder and convert the index to the actual label\n",
    "    if encoder_path is not None:\n",
    "        encoder = joblib.load(encoder_path)\n",
    "        dominant_label = encoder.inverse_transform([dominant_index])[0]\n",
    "    else:\n",
    "        dominant_label = dominant_index  # Fallback to numeric label if encoder is not provided\n",
    "    \n",
    "    return dominant_label, predictions\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    image_path = '/kaggle/input/img3333/6b7284dfeab7222691aa7e7472d8d4bc.jpg'\n",
    "    model_path = '/kaggle/working/plant_classification_indic_convnext.keras'\n",
    "    encoder_path = '/kaggle/working/label_encoder.pkl'  # Path to your saved encoder\n",
    "    \n",
    "    dominant_label, preds = predict_image(image_path, model_path, encoder_path)\n",
    "    print(\"Predicted Class:\", dominant_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/indiccsv/cleaned_indicleaf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_label'].unique()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6679331,
     "sourceId": 10767282,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6756298,
     "sourceId": 10874022,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
